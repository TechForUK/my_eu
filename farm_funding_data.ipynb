{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from collections import OrderedDict\n",
    "import copy\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "from ipyleaflet import Map, GeoJSON\n",
    "from ipywidgets import Label, Layout, VBox\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outcodes of Interest\n",
    "\n",
    "Which outcodes occur in our farm data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FARM_DATA_FILES = [\n",
    "    'DAERA-Table 1.csv',\n",
    "    'RPA-Table 1.csv',\n",
    "    'RPA2-Table 1.csv',\n",
    "    'SGRPID-Table 1.csv',\n",
    "    'WG-Table 1.csv'\n",
    "]\n",
    "farm_funding = pd.concat([\n",
    "    pd.read_csv(os.path.join('data', file))\n",
    "    for file in FARM_DATA_FILES\n",
    "])\n",
    "farm_funding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farm_funding.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I see some trailing spaces and lower case codes.\n",
    "farm_funding['CleanPostcodePrefix'] = farm_funding['PostcodePrefix_F202B'].str.strip().str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcodes = set(list(farm_funding['CleanPostcodePrefix']))\n",
    "len(outcodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They don't look very clean. Let's see how many are valid.\n",
    "\n",
    "This is based on https://en.wikipedia.org/wiki/Postcodes_in_the_United_Kingdom#Validation . It accepts the outward code and optionally the first digit of the inward code, because some of the data have said first digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_OUTCODE_RE = re.compile(\n",
    "    r'^([Gg][Ii][Rr] 0)'\n",
    "    r'|((([A-Za-z][0-9]{1,2})|'\n",
    "    r'(([A-Za-z][A-Ha-hJ-Yj-y][0-9]{1,2})|(([A-Za-z][0-9][A-Za-z])|([A-Za-z][A-Ha-hJ-Yj-y][0-9]?[A-Za-z])))'\n",
    "    r')( [0-9])?)$'\n",
    ")\n",
    "valid_outcodes = set([\n",
    "    outcode for outcode in outcodes\n",
    "    if VALID_OUTCODE_RE.match(outcode)\n",
    "])\n",
    "len(valid_outcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcodes - valid_outcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farm_funding[farm_funding['PostcodePrefix_F202B'] == 'CRO ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farm_funding[farm_funding['PostcodePrefix_F202B'] == 'WA 6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postcode Cleaning\n",
    "\n",
    "Are they districts, or are some sectors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukpostcodes = pd.read_csv('data/ukpostcodes.csv')\n",
    "ukpostcodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukpostcodes['squashed'] = ukpostcodes['postcode'].str.replace(r'\\s+', '')\n",
    "ukpostcodes['district'] = ukpostcodes['postcode'].str.replace(r'^(.+)\\s.+$', r'\\1')\n",
    "ukpostcodes['sector'] = ukpostcodes['postcode'].str.replace(r'^(.+)\\s([0-9]).+$', r'\\1 \\2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukpostcodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ukpostcodes['district'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(\n",
    "    pd.DataFrame({'district': ukpostcodes['district'].unique()}),\n",
    "    farm_funding,\n",
    "    left_on='district', right_on='PostcodePrefix_F202B').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(\n",
    "    pd.DataFrame({'sector': ukpostcodes['sector'].unique()}),\n",
    "    farm_funding,\n",
    "    left_on='sector', right_on='PostcodePrefix_F202B').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it looks like most of them are districts. However, some have trailing spaces, and others don't."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Against Authoritative List\n",
    "\n",
    "This is from https://www.freemaptools.com/download-uk-postcode-lat-lng.htm ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcode_to_location = pd.read_csv('data/postcode-outcodes.csv').drop('id', axis=1)\n",
    "outcode_to_location.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcode_to_location.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_farm_funding = pd.merge(farm_funding, outcode_to_location, left_on='CleanPostcodePrefix', right_on='postcode', validate='m:1')\n",
    "clean_farm_funding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it's not too bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The miDrive Data\n",
    "\n",
    "Not bad (after some fixing for the PL area: https://github.com/miDrive/uk-outcode-geometry/pull/1), but missing Northern Ireland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_ROOT = 'data/uk-outcode-geometry-master/json/'\n",
    "all_outcodes = None\n",
    "for area_file in os.listdir(JSON_ROOT):\n",
    "    with open(os.path.join(JSON_ROOT, area_file)) as f:\n",
    "        data = json.load(f)\n",
    "    if all_outcodes is None:\n",
    "        all_outcodes = data\n",
    "    else:\n",
    "        all_outcodes['features'].extend(data['features'])\n",
    "        \n",
    "len(all_outcodes['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outcodes['features'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Map(center=(54.3781, 3.4360), zoom = 5)\n",
    "geo_json = GeoJSON(data=all_outcodes)\n",
    "m.add_layer(geo_json)\n",
    "# m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Google Fusion Tables Data\n",
    "\n",
    "From [Fusion Tables](https://fusiontables.google.com/data?docid=1jgWYtlqGSPzlIa-is8wl1cZkVIWEm_89rWUwqFU).\n",
    "\n",
    "License: http://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_districts_raw = pd.read_csv('data/uk_postcode_districts.csv')\n",
    "fusion_districts_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have some duplicates. We don't want that for merging.\n",
    "fusion_districts_raw_prefixes = list(fusion_districts_raw['Postcode district'])\n",
    "fusion_districts_duplicate_prefixes = set([\n",
    "    prefix for prefix in fusion_districts_raw_prefixes\n",
    "    if fusion_districts_raw_prefixes.count(prefix) > 1\n",
    "])\n",
    "fusion_districts_duplicate_prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's keep the largest shape for each one, on the assumption that it's the most detailed.\n",
    "fusion_districts_raw['Area len'] = fusion_districts_raw['Area data'].apply(len)\n",
    "fusion_districts_raw[fusion_districts_raw['Postcode district'] == 'BT21 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_districts_raw = fusion_districts_raw.sort_values(['Postcode district', 'Area len'])\n",
    "fusion_districts_raw.drop_duplicates('Postcode district', keep='last', inplace=True)\n",
    "fusion_districts_raw[fusion_districts_raw['Postcode district'] == 'BT21 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_districts_raw = fusion_districts_raw.drop('Area len', axis=1)\n",
    "fusion_districts_raw[fusion_districts_raw['Postcode district'] == 'BT21 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_districts_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_districts_raw.to_csv('data/uk_postcode_districts_deduplicated.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then ran the `togeojson` utility to get GeoJSON..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/uk_postcode_districts_deduplicated.json') as file:\n",
    "    fusion_districts = json.load(file)\n",
    "len(fusion_districts['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_districts_prefixes = [\n",
    "    feature['properties']['name']\n",
    "    for feature in fusion_districts['features']\n",
    "]\n",
    "len(fusion_districts_prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should not have any duplicates any more.\n",
    "set([\n",
    "    prefix for prefix in fusion_districts_prefixes\n",
    "    if fusion_districts_prefixes.count(prefix) > 1\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_district_map(data):\n",
    "    m = Map(center=(54.3781, 3.4360), zoom = 5)\n",
    "    label = Label(layout=Layout(width='100%'))\n",
    "    \n",
    "    layer = GeoJSON(data=data, hover_style={'fillColor': 'red'})\n",
    "    \n",
    "    def hover_handler(event=None, id=None, properties=None):\n",
    "        label.value = properties['name']\n",
    "\n",
    "    layer.on_hover(hover_handler)\n",
    "    m.add_layer(layer)\n",
    "\n",
    "    return VBox([m, label])\n",
    "make_district_map(fusion_districts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = valid_outcodes - set(fusion_districts_prefixes)\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_districts_raw[fusion_districts_raw['Postcode district'].str.startswith('B1')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it looks like we have to aggregate some prefixes to fit the map data, and vice versa. However, it's not too bad. Let's see what it looks like if we just use the data for which we have map shapes.\n",
    "\n",
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farm_funding_map = farm_funding[\n",
    "    farm_funding['CleanPostcodePrefix'].isin(set(fusion_districts_prefixes))\n",
    "]\n",
    "farm_funding_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 * farm_funding_map.shape[0] / farm_funding.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farm_funding_by_district = farm_funding_map.groupby('CleanPostcodePrefix').aggregate(OrderedDict([\n",
    "    ('OtherEAGFTotal', sum),\n",
    "    ('DirectEAGFTotal', sum),\n",
    "    ('RuralDevelopmentTotal', sum),\n",
    "    ('Total', [sum, len])\n",
    "]))\n",
    "farm_funding_by_district.reset_index(inplace=True)\n",
    "farm_funding_by_district.columns = [\n",
    "    'CleanPostcodePrefix',\n",
    "    'otherEAGF',\n",
    "    'directEAGF',\n",
    "    'ruralDevelopment',\n",
    "    'total',\n",
    "    'count'\n",
    "]\n",
    "PROPERTY_COLUMNS = set(farm_funding_by_district.columns) - set(['CleanPostcodePrefix'])\n",
    "for column in PROPERTY_COLUMNS:\n",
    "    farm_funding_by_district[column] = farm_funding_by_district[column].round().astype('int32')\n",
    "farm_funding_by_district"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_districts_features = pd.DataFrame.from_dict({\n",
    "    'name': [feature['properties']['name'] for feature in fusion_districts['features']],\n",
    "    'geometry': [feature['geometry'] for feature in fusion_districts['features']],\n",
    "})\n",
    "fusion_districts_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_districts_data = pd.merge(\n",
    "    fusion_districts_features, farm_funding_by_district,\n",
    "    left_on='name', right_on='CleanPostcodePrefix', validate='m:1')\n",
    "fusion_districts_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_districts_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fusion_districts_data['total'] / fusion_districts_data['count']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_funding_data_geo_json(fusion_districts_data):\n",
    "    def make_feature(row):\n",
    "        properties = {\n",
    "            property: row[property] for property in PROPERTY_COLUMNS\n",
    "        }\n",
    "        properties['name'] = row['name']\n",
    "        return {\n",
    "            'type': 'Feature',\n",
    "            'geometry': row['geometry'],\n",
    "            'properties': properties\n",
    "        }\n",
    "    features = list(fusion_districts_data.apply(make_feature, axis=1))\n",
    "    return { 'type': 'FeatureCollection', 'features': features }\n",
    "with open('data/farm_funding_data.geo.json', 'w') as file:\n",
    "    json.dump(make_funding_data_geo_json(fusion_districts_data), file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file is quite large (14MB). Let's see where it comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_districts_features['geometry_size'] = \\\n",
    "    fusion_districts_features['geometry'].apply(lambda x: len(json.dumps(x)))\n",
    "fusion_districts_features.sort_values('geometry_size', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_districts_features.hist('geometry_size', bins=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_districts_features['geometry_size'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_districts_features['geometry_size'].sum() / fusion_districts_features.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it's not that there are a few outliers that account for most of it; it's pretty widely spread.\n",
    "\n",
    "# Aggregation\n",
    "\n",
    "What if we aggregate the data into larger units? NUTS2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcodes_to_nuts3 = pd.read_csv('data/pc2018_uk_NUTS-2016_v1.0.csv.gz', sep=';', quotechar=\"'\")\n",
    "postcodes_to_nuts3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcodes_to_nuts3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcodes_to_nuts3_unique = postcodes_to_nuts3['NUTS3'].unique()\n",
    "len(postcodes_to_nuts3_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts3 = pd.read_csv('data/NUTS_Level_3_January_2018_Ultra_Generalised_Clipped_Boundaries_in_the_United_Kingdom.csv')\n",
    "nuts3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(nuts3['nuts318cd']) - set(postcodes_to_nuts3_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(postcodes_to_nuts3_unique) - set(nuts3['nuts318cd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts3[~nuts3['nuts318cd'].isin(postcodes_to_nuts3_unique)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, I think it covers all of them, except for some new, more granular codes in Northern Ireland, which were apparently added after 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_postcode_prefix_to_nuts3(postcode_prefixes, postcodes_to_nuts3):\n",
    "    postcode_prefixes_df = pd.DataFrame({ 'prefix': postcode_prefixes })\n",
    "    postcode_prefix_lengths = postcode_prefixes_df['prefix'].str.len()\n",
    "    \n",
    "    def match_with_prefix_length(n):\n",
    "        postcode_prefixes_n = postcode_prefixes_df[postcode_prefix_lengths == n]\n",
    "        \n",
    "        postcodes_to_nuts3_n = postcodes_to_nuts3.copy(deep=True)\n",
    "        postcodes_to_nuts3_n['prefix'] = \\\n",
    "            postcodes_to_nuts3_n['CODE'].str.replace(r'\\s+', '').str.slice(0, n)\n",
    "        \n",
    "        return pd.merge(postcode_prefixes_n, postcodes_to_nuts3_n, on='prefix')\n",
    "    \n",
    "    postcode_prefix_length_range = range(\n",
    "        postcode_prefix_lengths.min(), postcode_prefix_lengths.max() + 1)\n",
    "    return pd.concat([\n",
    "        match_with_prefix_length(prefix_length)\n",
    "        for prefix_length in postcode_prefix_length_range\n",
    "    ])\n",
    "prefix_to_nuts = match_postcode_prefix_to_nuts3(\n",
    "    clean_farm_funding['CleanPostcodePrefix'].unique(), postcodes_to_nuts3)\n",
    "prefix_to_nuts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_to_nuts['NUTS2'] = prefix_to_nuts['NUTS3'].str.slice(0, 4)\n",
    "prefix_to_nuts['NUTS1'] = prefix_to_nuts['NUTS3'].str.slice(0, 3)\n",
    "prefix_to_nuts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_to_nuts.groupby('prefix')['NUTS3'].nunique().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_to_nuts.groupby('prefix')['NUTS2'].nunique().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_to_nuts.groupby('prefix')['NUTS1'].nunique().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_to_nuts.groupby('prefix').filter(lambda x: x['NUTS1'].nunique() > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_to_nuts[prefix_to_nuts['prefix'] == 'CH7']['NUTS3'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_to_nuts[prefix_to_nuts['prefix'] == 'L37']['NUTS2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_to_nuts[prefix_to_nuts['prefix'] == 'L37']['NUTS2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
